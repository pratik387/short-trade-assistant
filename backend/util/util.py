# @role: Helper utilities like date handling, price rounding etc.
# @used_by: exit_service.py, portfolio_router.py, technical_analysis_exit.py, tick_listener.py
# @filter_type: utility
# @tags: utility, helpers, tools
import pandas as pd
from pathlib import Path
import random
import math
import json
import time
import functools
from jobs.refresh_holidays import download_nse_holidays
from exceptions.exceptions import InvalidTokenException, DataUnavailableException
from brokers.kite.kite_client import set_access_token_from_file
from config.logging_config import get_loggers

logger, trade_logger = get_loggers()

HOLIDAY_FILE = Path(__file__).resolve().parents[1] / "assets" / "nse_holidays.json"
def is_market_active(date=None):
    """
    Check if the market is active for a given date/time.
    Loads holiday dates from the JSON file and applies weekend and session checks.
    Returns True if open, False if closed.
    """
    try:
        # Normalize date parameter or use today's date
        if date is None:
            check_date = pd.Timestamp.now(tz="Asia/Kolkata")
        else:
            check_date = pd.Timestamp(date)
            if check_date.tzinfo is None:
                check_date = check_date.tz_localize("Asia/Kolkata")
            else:
                check_date = check_date.tz_convert("Asia/Kolkata")

        # Weekend check (Saturday=5, Sunday=6)
        if check_date.weekday() >= 5:
            logger.info(f"‚õî {check_date.date()} is weekend; market closed.")
            return False

        # Load holiday entries
        try:
            with open(HOLIDAY_FILE, "r", encoding="utf-8") as f:
                items = json.load(f)
        except FileNotFoundError:
            logger.error(f"‚ö†Ô∏è Holidays file not found at {HOLIDAY_FILE!s}. Downloading fresh copy‚Ä¶")
            res = download_nse_holidays()
            if res.get("status") == "success":
                with open(HOLIDAY_FILE, "r", encoding="utf-8") as f:
                    items = json.load(f)
            else:
                logger.info("‚ùå Could not fetch holidays; assuming market is open.")
                return True

        # Parse holiday dates
        dates = []
        for item in items:
            # support both keys
            raw = item.get("tradingDate") or item.get("holidayDate")
            try:
                dt = pd.to_datetime(raw, format="%d-%b-%Y", errors="coerce").normalize()
                if not pd.isna(dt):
                    dates.append(dt)
            except Exception:
                continue

        if check_date in dates:
            logger.info(f"‚õî {check_date.date()} is a market holiday.")
            return False

        # Market session hours: 9:15am ‚Äì 3:30pm IST
        open_time = check_date.replace(hour=9, minute=15)
        close_time = check_date.replace(hour=15, minute=30)
        is_open = open_time <= check_date <= close_time
        logger.info(f"Market status at {check_date.time()}: {'Open' if is_open else 'Closed'}")
        return is_open

    except Exception as e:
        logger.error(f"‚ö†Ô∏è Could not determine market status: {e}")
        return False
    
def is_trading_day(date):
    """
    Returns True if the given date is a valid NSE trading day (not weekend, not holiday).
    Uses same holiday logic as is_market_active().
    """
    try:
        dt = pd.Timestamp(date).normalize()

        # Weekend
        if dt.weekday() >= 5:
            return False

        # Holidays (same logic)
        if not HOLIDAY_FILE.exists():
            download_nse_holidays()

        with open(HOLIDAY_FILE, "r", encoding="utf-8") as f:
            items = json.load(f)
            holidays = [
                pd.to_datetime(item.get("tradingDate") or item.get("holidayDate"), format="%d-%b-%Y", errors="coerce").normalize()
                for item in items
            ]
            holidays = [d for d in holidays if not pd.isna(d)]

        return dt not in holidays

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è is_trading_day fallback triggered: {e}")
        return True  # fallback to assume trading day

    
def retry(max_attempts=3, base_delay=1, exceptions=(Exception,), exclude=(InvalidTokenException,)):
    """
    Decorator to retry a function if it raises specified exceptions.

    Args:
        max_attempts (int): Number of retry attempts before giving up.
        delay (int): Delay between retries in seconds.
        exceptions (tuple): Tuple of exception classes to catch.

    Example:
        @retry(max_attempts=5, delay=1)
        def fetch_data(): ...
    """
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(1, max_attempts + 1):
                try:
                    return func(*args, **kwargs)
                except InvalidTokenException as e:
                    logger.warning(f"[Retry {attempt}/{max_attempts}] Actual token error: {e}")
                    set_access_token_from_file()
                    time.sleep(base_delay)
                    continue

                except exceptions as e:
                    err_msg = str(e).lower()

                    # üü• Zerodha-specific behavior: invalid symbol triggers 'invalid token'
                    if "invalid token" in err_msg:
                        logger.error(f"üîç Symbol not available in NSE during {func.__name__}")
                        raise DataUnavailableException(f"Symbol not available in NSE : {e}")

                    if attempt == max_attempts:
                        logger.error(f"‚ùå Max retries exceeded for {func.__name__}: {e}")
                        raise

                    backoff = base_delay * (2 ** (attempt - 1))
                    jitter = random.uniform(0, 0.3 * backoff)
                    wait_time = round(backoff + jitter, 2)

                    logger.warning(f"[Retry {attempt}/{max_attempts}] {func.__name__} failed: {e} -> waiting {wait_time}s")
                    time.sleep(wait_time)

        return wrapper
    return decorator



def calculate_dynamic_exit_threshold(config, df, days_held):
    """
    Compute a dynamic score threshold for exit based on time decay and volatility.

    Args:
        config (dict): Full config object with 'exit_filters' and 'dynamic_threshold'
        df (pd.DataFrame): Enriched price data with 'ATR' column
        days_held (int): Days the stock has been held

    Returns:
        float: The computed dynamic threshold
    """
    dyn_config = config.get("dynamic_threshold", {})
    exit_filters = config.get("exit_filters", {})

    max_possible_score = 0
    for name, f in exit_filters.items():
        if not f.get("enabled", False):
            continue
        if name == "exit_time_decay_filter" and "weight_schedule" in f:
            scheduled_weights = [w.get("weight", 0) for w in f["weight_schedule"]]
            max_possible_score += max(scheduled_weights) if scheduled_weights else 0
        else:
            weight = f.get("weight", 0)
            if weight > 0:
                max_possible_score += weight

    base_ratio = dyn_config.get("base_weight_ratio", 0.25)
    min_threshold = dyn_config.get("min_threshold", 5)
    time_decay_rate = dyn_config.get("time_decay_rate", 0.3)
    time_weight_reduction = dyn_config.get("time_weight_reduction", 0.5)
    vol_scaling_factor = dyn_config.get("volatility_scaling_factor", 0.2)

    base_threshold = max(min_threshold, base_ratio * max_possible_score)
    time_decay = 1 - math.exp(-time_decay_rate * days_held)

    if "ATR" not in df.columns or df["ATR"].isna().all():
        return min_threshold

    current_atr = df["ATR"].iloc[-1]
    avg_atr = df["ATR"].rolling(window=14, min_periods=1).mean().fillna(0).iloc[-1]

    if avg_atr == 0:
        vol_adj = 1
    else:
        vol_adj = 1 + vol_scaling_factor * (current_atr / avg_atr)

    dynamic_threshold = base_threshold * (1 - time_weight_reduction * time_decay) * vol_adj
    return dynamic_threshold

